<!DOCTYPE html>
<html lang="en">
    <head>
        <title></title>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <style>
            body {
                margin: 0px;
                overflow: hidden;
                background-color: #000000;
            }
            #audioFile{
            position: absolute;
            top: 0;
            left: 0;
            z-index: 999;
            background: white;
            }
            audio{
                position: absolute;
                bottom: 1em;
            }
        </style>
    </head>
    <body>
            <script src="js/third-party/threejs/three.js"></script>
            <script src="js/third-party/threejs/vr/ViveController.js"></script>
            <script src="js/third-party/threejs/vr/WebVR.js"></script>
    
            <script src="js/third-party/threejs/loaders/OBJLoader.js"></script>
            <script src="js/third-party/threejs/effects/VREffect.js"></script>
            <script src="js/third-party/threejs/effects/StereoEffect.js"></script>
    
            <script src="js/third-party/threejs/controls/VRControls.js"></script>
            <script src="js/third-party/threejs/controls/DeviceOrientationControls.js"></script>
            <script src="js/third-party/threejs/controls/OrbitControls.js"></script>
    
            <script src="js/third-party/TweenMax.min.js"></script>
            <script src="js/third-party/perlin.js"></script>
    
            <script src="js/utils/helpers.js"></script>
            <script src="js/utils/AudioReactive.js"></script>

            <input id="audioFile" name="newAudioFile" type="file" accept="audio/*">
            <div class="audio-container"></div>

            <script>
                var audioFile = document.querySelector('#audioFile');
                audioFile.onchange = (event) =>{
    
                audioFile = event.target.files;
                var songName = audioFile[0].name;
                console.log(`Now playing ${audioFile[0].name}`)
                
                //Creates a temporary url for the file input in this case the audio that is being uploaded
                // audioPlayer.src = URL.createObjectURL(audioFile[0])
                audioPlayer = new Audio(URL.createObjectURL(audioFile[0]))
                var audioDiv = document.querySelector('.audio-container');
                
                //Prevents local memory of audio files so you can create a new instance on upload
                audioDiv.firstChild !== null ? (audioDiv.firstElementChild.remove(), (audioDiv.appendChild(audioPlayer))) : audioDiv.appendChild(audioPlayer);
                audioPlayer.load(), audioPlayer.play(), audioPlayer.controls = true;

                 // AnalyserNode is necessary to provide real-time frequency and time-domain analysis information. It is an AudioNode that passes the audio stream unchanged from the input to the output, but allows you to take the generated data, process it, and create audio visualizations.
                var audioCtx = new(window.AudioContext || window.webkitAudioContext)();
                var analyser = audioCtx.createAnalyser();
                
                source = audioCtx.createMediaElementSource(audioPlayer) // Uploaded audio becomes the source for the media stream
                source.connect(analyser)
                analyser.connect(audioCtx.destination)
                console.log(analyser.connect(audioCtx.destination))

                analyser.fftSize = 256; // 256 or 2048
                var bufferLength = analyser.frequencyBinCount;
                console.log(bufferLength)
                var dataArray = new Uint8Array(bufferLength)

            }
            </script>
    </body>
</html>